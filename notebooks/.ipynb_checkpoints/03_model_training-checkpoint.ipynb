{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb862c9-b0f3-4a84-a428-e850e923e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ajouter le dossier parent de 'src' au chemin Python\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650dc714",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Entraînement des Modèles - VERSION CORRIGÉE\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1 - IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.features.feature_engineer import FeatureEngineer\n",
    "from src.models.model_trainer import ModelTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"🤖 Entraînement des Modèles - VERSION CORRIGÉE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4101b9-ab44-46fb-9fcd-058800eb7683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Méthodes disponibles:\n",
      "  - clean_data\n",
      "  - create_features\n",
      "  - fit\n",
      "  - fit_transform\n",
      "  - get_metadata_routing\n",
      "  - get_params\n",
      "  - scaler\n",
      "  - set_output\n",
      "  - set_params\n",
      "  - transform\n"
     ]
    }
   ],
   "source": [
    "# Dans une cellule de votre notebook, vérifiez les méthodes disponibles\n",
    "fe = FeatureEngineer()\n",
    "print(\"Méthodes disponibles:\")\n",
    "for method in dir(fe):\n",
    "    if not method.startswith('_'):  # Ne pas afficher les méthodes privées\n",
    "        print(f\"  - {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63a331c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Données chargées: 100000 transactions\n",
      "1. Création des features...\n",
      "2. Nettoyage des données...\n",
      "3. Préparation pour ML...\n",
      "   NaN après clean_data: 0\n",
      "✅ Dimensions finales: X(100000, 38), y(100000,)\n"
     ]
    }
   ],
   "source": [
    "# Cellule 2 - CHARGEMENT ET PRÉPARATION CORRIGÉE\n",
    "loader = DataLoader()\n",
    "df = loader.load_raw_data()\n",
    "\n",
    "fe = FeatureEngineer()\n",
    "\n",
    "# ⚠️ CORRECTION : utilisez create_features() et clean_data()\n",
    "print(\"1. Création des features...\")\n",
    "df_engineered = fe.create_features(df)  # Bonne méthode\n",
    "\n",
    "print(\"2. Nettoyage des données...\")\n",
    "df_clean = fe.clean_data(df_engineered)  # Nettoyage supplémentaire\n",
    "\n",
    "print(\"3. Préparation pour ML...\")\n",
    "X = df_clean.drop('Class', axis=1)\n",
    "y = df_clean['Class']\n",
    "\n",
    "# Vérification des NaN\n",
    "print(f\"   NaN après clean_data: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# Sécurité supplémentaire\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "print(f\"✅ Dimensions finales: X{X.shape}, y{y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf80c03",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Après split train/test:\n",
      "   X_train: (80000, 38), y_train: (80000,)\n",
      "   X_test: (20000, 38), y_test: (20000,)\n",
      "   Fraudes dans y_train: 136, y_test: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda3/envs/fraud-detection/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Après SMOTE:\n",
      "   X_train_res: (159728, 38)\n",
      "   y_train_res: (159728,)\n",
      "   Distribution: {0: 79864, 1: 79864}\n"
     ]
    }
   ],
   "source": [
    "# Cellule 3 - SPLIT ET SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"📊 Après split train/test:\")\n",
    "print(f\"   X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"   X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(f\"   Fraudes dans y_train: {y_train.sum()}, y_test: {y_test.sum()}\")\n",
    "\n",
    "# Application de SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"🔄 Après SMOTE:\")\n",
    "print(f\"   X_train_res: {X_train_res.shape}\")\n",
    "print(f\"   y_train_res: {y_train_res.shape}\")\n",
    "print(f\"   Distribution: {pd.Series(y_train_res).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f2ccf5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Entraînement de logistic_regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bala/anaconda3/envs/fraud-detection/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ logistic_regression - AUC: 0.9803\n",
      "🔧 Entraînement de random_forest...\n",
      "✅ random_forest - AUC: 0.9998\n",
      "🔧 Entraînement de xgboost...\n",
      "✅ xgboost - AUC: 0.9999\n",
      "🔧 Entraînement de lightgbm...\n",
      "[LightGBM] [Info] Number of positive: 79864, number of negative: 79864\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9206\n",
      "[LightGBM] [Info] Number of data points in the train set: 159728, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "✅ lightgbm - AUC: 0.9999\n",
      "🎯 MEILLEUR MODÈLE: AUC = 0.9999\n"
     ]
    }
   ],
   "source": [
    "# Cellule 4 - ENTRAÎNEMENT DES MODÈLES\n",
    "trainer = ModelTrainer()\n",
    "results = trainer.train_models(X_train_res, y_train_res, X_test, y_test)\n",
    "\n",
    "best_model, best_score = trainer.get_best_model()\n",
    "print(f\"🎯 MEILLEUR MODÈLE: AUC = {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8bbfdd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a5c7f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 RAPPORT DE CLASSIFICATION:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19966\n",
      "           1       0.84      0.94      0.89        34\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.92      0.97      0.94     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "\n",
      "🎯 MATRICE DE CONFUSION:\n",
      "[[19960     6]\n",
      " [    2    32]]\n"
     ]
    }
   ],
   "source": [
    "# Cellule 5 - Évaluation détaillée\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Prédictions du meilleur modèle\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"📊 RAPPORT DE CLASSIFICATION:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\n🎯 MATRICE DE CONFUSION:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a27774-115f-4b22-a33e-0f2d2f5cb092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modèle enregistré: models/fraud_detector_20250927_210157.pkl\n",
      "✅ Pipeline complet enregistré: models/fraud_pipeline_20250927_210157.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import datetime\n",
    "\n",
    "# Créer le dossier models s'il n'existe pas\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Nom du fichier avec timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f'models/fraud_detector_{timestamp}.pkl'\n",
    "\n",
    "# Enregistrement du modèle\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"✅ Modèle enregistré: {model_filename}\")\n",
    "\n",
    "# Enregistrement aussi du feature engineer et des métadonnées\n",
    "pipeline = {\n",
    "    'model': best_model,\n",
    "    'feature_engineer': fe,\n",
    "    'model_type': type(best_model).__name__,\n",
    "    'auc_score': best_score,\n",
    "    'timestamp': timestamp,\n",
    "    'features_used': X.columns.tolist()\n",
    "}\n",
    "\n",
    "pipeline_filename = f'models/fraud_pipeline_{timestamp}.pkl'\n",
    "joblib.dump(pipeline, pipeline_filename)\n",
    "print(f\"✅ Pipeline complet enregistré: {pipeline_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87dcc0-996f-4f99-9334-7c2d3227ca4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
